{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'skimage'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d135b02b983b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mread_transcription\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mrt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mread_SVG\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msvgread\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcrop_svg_outline\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msvgcrop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mresize_images\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mresize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbinarization\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/UniBern/github/4.5_biologists/src/main/py/kws/crop_svg_outline.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImageDraw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'skimage'"
     ]
    }
   ],
   "source": [
    "import os, numpy as np\n",
    "import platform\n",
    "import argparse\n",
    "import read_transcription as rt\n",
    "import read_SVG as svgread\n",
    "import crop_svg_outline as svgcrop\n",
    "import resize_images as resize\n",
    "import binarization as binary\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = {}\n",
    "\n",
    "# directories\n",
    "paths[\"images\"] = os.path.join('data', 'images')\n",
    "paths[\"binarized_images\"] = os.path.join('data', 'binarized_images')\n",
    "paths[\"word_images\"] = os.path.join('data', 'word_images')\n",
    "paths[\"resized_word_images\"] = os.path.join('data', 'resized_word_images')\n",
    "paths[\"svg\"] = os.path.join('data', 'ground-truth', 'locations')\n",
    "\n",
    "# files\n",
    "paths[\"transcription.txt\"] = os.path.join('data', 'ground-truth', 'transcription.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in paths:\n",
    "    if (not os.path.exists(paths[k]) and paths[k][:-4] != \".txt\"):\n",
    "        os.makedirs(paths[k])\n",
    "\n",
    "\n",
    "list_of_images = sorted(os.listdir(paths[\"images\"]))\n",
    "list_of_svg = sorted(os.listdir(paths[\"svg\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    if not os.listdir(paths[\"binarized_images\"]) or not os.listdir(paths[\"word_images\"]) :\n",
    "        # ----- ID linking----#\n",
    "        ID_dict = rt.read_transcription(file_name=paths[\"transcription.txt\"], output=\"ID_dict\")\n",
    "\n",
    "        # --- processing pages (binarization and cropping out words) --- #\n",
    "        i = 0\n",
    "        for page_no, page in enumerate(list_of_images):\n",
    "            print(\"processing page \", i+1, \" out of \", len(list_of_images))\n",
    "\n",
    "            image = plt.imread(os.path.join(paths[\"images\"], page))\n",
    "            svg = os.path.join(paths[\"svg\"], list_of_svg[page_no])\n",
    "            coord_list = svgread.extract_SVG_masks(svg)\n",
    "\n",
    "            img_name = page[:-4] + \".png\"\n",
    "            image_out = os.path.join(paths[\"binarized_images\"], img_name)\n",
    "\n",
    "            image_bin = binary.binarize_image(image, block_size=101)  # binarize image using local thresholding\n",
    "            binary.save_image_png(image_out, image_bin)\n",
    "\n",
    "            svg_in = os.path.join(paths[\"binarized_images\"], img_name)\n",
    "            svgcrop.crop_svg_outline(svg_in, ID_dict=ID_dict, svg_coordinates=coord_list, output_path=paths[\"word_images\"])  # crop individual words by polygon outline\n",
    "\n",
    "            i += 1\n",
    "\n",
    "\n",
    "    # --- get median word width and height (for resizing) --- #\n",
    "    base = os.getcwd()\n",
    "    list_of_wordimages = sorted(os.listdir(paths[\"word_images\"]))\n",
    "    os.chdir(paths[\"word_images\"])\n",
    "    median_word_width, median_word_height = resize.median_wh(list_of_wordimages) #    word_lengths = [len(word) for word in word_dict]\n",
    "    os.chdir(base)\n",
    "\n",
    "\n",
    "    # --- processing individual word images (resizing) --- #\n",
    "    if not os.listdir(paths[\"resized_word_images\"]):\n",
    "        i = 0\n",
    "        for file in list_of_wordimages:\n",
    "            if i%100 == 0:\n",
    "                print(\"processing word-image \", i+1, \" out of \", len(list_of_wordimages))\n",
    "            file_in = os.path.join(paths[\"word_images\"], file)\n",
    "            resize.resize_image(file_in, height_new=median_word_height, width_new = median_word_width, output_path=paths[\"resized_word_images\"])\n",
    "\n",
    "            i += 1\n",
    "\n",
    "    print(\"Binary images of individual words extracted and rescaled to\", median_word_width, \"x\", median_word_height, \"pixel (width x height).\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
